{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4c3733d-971b-468c-9d06-34cb49d1113c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 28, 28)\n",
      "Test data shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "(X_train_raw, y_train_raw), (X_test_raw, y_test_raw) = mnist.load_data()\n",
    "\n",
    "# Normalize the data to the range [0, 1]\n",
    "X_train_raw = X_train_raw.astype('float32') / 255\n",
    "X_test_raw = X_test_raw.astype('float32') / 255\n",
    "\n",
    "print(f\"Training data shape: {X_train_raw.shape}\")\n",
    "print(f\"Test data shape: {X_test_raw.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "748cf380-6429-4dea-bb77-1c0180b8aea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X_train_raw.reshape(X_train_raw.shape[0],-1).T\n",
    "X_test = X_test_raw.reshape(X_test_raw.shape[0],-1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f62b2c49-72af-4821-a550-50a0c25af8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5  0.3  0.25 0.11 0.72]]\n",
      "1\n",
      "Weights 0: (3, 1)\n",
      "Biases 0: (3, 1)\n",
      "Weights 1: (2, 3)\n",
      "Biases 1: (2, 1)\n",
      "Weights 2: (3, 2)\n",
      "Biases 2: (3, 1)\n",
      "Weights 3: (4, 3)\n",
      "Biases 3: (4, 1)\n",
      "[array([[0.49887998],\n",
      "       [0.13534154],\n",
      "       [0.77950362]]), array([[0.98319766, 0.72767452, 0.66574771],\n",
      "       [0.78758119, 0.30921274, 0.96183345]]), array([[0.05273694, 0.24956142],\n",
      "       [0.9352311 , 0.77955523],\n",
      "       [0.55368971, 0.84272271]]), array([[0.58965514, 0.93479104, 0.07933925],\n",
      "       [0.99754637, 0.27942419, 0.95517746],\n",
      "       [0.90631309, 0.68675105, 0.83638184],\n",
      "       [0.73677206, 0.61592439, 0.65713019]])]\n"
     ]
    }
   ],
   "source": [
    "def softmax(array):\n",
    "    # Subtract the max value to prevent overflow during exponentiation\n",
    "    exp_array = np.exp(array - np.max(array, axis=-1, keepdims=True))\n",
    "    return exp_array / np.sum(exp_array, axis=-1, keepdims=True)\n",
    "\n",
    "class AnnStructure:\n",
    "    def __init__(self,data,hidden_sizes,output_size):\n",
    "        \n",
    "        self.data = data\n",
    "        #data must be stored such that len(data) == input_size\n",
    "        self.input_size = self.data.shape[0]\n",
    "        #array of size for each hidden layer\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        #size of the output layer\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        #definition of the weights and biases\n",
    "        self.W = []\n",
    "        self.b = []\n",
    "\n",
    "        # Weights and biases for input to first hidden layer\n",
    "        self.W.append(np.random.rand(hidden_sizes[0],self.input_size))\n",
    "        self.b.append(np.zeros((hidden_sizes[0],1)))\n",
    "\n",
    "        # Weights and biases for connections between hidden layers\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            self.W.append(np.random.rand(hidden_sizes[i],hidden_sizes[i-1]))\n",
    "            self.b.append(np.zeros((hidden_sizes[i],1)))\n",
    "\n",
    "        # Weights and biases for last hidden layer to output layer\n",
    "        self.W.append(np.random.rand(output_size,hidden_sizes[-1]))\n",
    "        self.b.append(np.zeros((output_size,1)))\n",
    "        \n",
    "        #transform to numpy\n",
    "        #self.W = np.array(self.W,dtype=object)\n",
    "        #self.b = np.array(self.b,dtype=object)\n",
    "        \n",
    "        #definition of the output of each layer\n",
    "        self.Z = []\n",
    "        \n",
    "    def feedforward(self):\n",
    "        \n",
    "        print(f\"W[0] = {self.W[0]} \\n\\n data = {self.data} \\n\")\n",
    "        self.Z.append(np.maximum(0,np.dot(self.W[0],self.data)))\n",
    "        \n",
    "        for i in range(1,len(self.W)-1):\n",
    "            self.Z.append(np.maximum(0,np.dot(self.W[i],self.Z[i-1])))\n",
    "        \n",
    "        self.Z.append(softmax(np.dot(self.W[-1],self.Z[-2])))\n",
    "        \n",
    "        print(f\"Z_output is: {self.Z[-1]} \\nZ_output shape is: {self.Z[-1].shape}\")\n",
    "            \n",
    "# Example usage\n",
    "data = np.array([[0.5, 0.3, 0.25, 0.11, 0.72]])  # Sample data with 5 features\n",
    "data = data\n",
    "print(data)\n",
    "print(len(data))\n",
    "hidden_sizes = [3, 2, 3]  # three hidden layers with 3, 2 and 3 neurons respectively\n",
    "output_size = 4  # Output layer with 4 neurons\n",
    "\n",
    "trial_ann = AnnStructure(data, hidden_sizes, output_size)\n",
    "\n",
    "# Printing the shapes of the weights and biases for verification\n",
    "for i in range(len(trial_ann.W)):\n",
    "    print(f\"Weights {i}: {trial_ann.W[i].shape}\")\n",
    "    print(f\"Biases {i}: {trial_ann.b[i].shape}\")\n",
    "\n",
    "    \n",
    "print(trial_ann.W)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f6c2587-331b-43d5-b577-93d00662006b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
      " 0.49411765 0.53333336 0.6862745  0.10196079 0.6509804  1.\n",
      " 0.96862745 0.49803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
      " 0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19215687\n",
      " 0.93333334 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.9843137  0.3647059  0.32156864\n",
      " 0.32156864 0.21960784 0.15294118 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07058824 0.85882354 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.7764706  0.7137255\n",
      " 0.96862745 0.94509804 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
      " 0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05490196 0.00392157 0.6039216  0.99215686 0.3529412\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.54509807 0.99215686 0.74509805 0.00784314 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04313726\n",
      " 0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.13725491 0.94509804\n",
      " 0.88235295 0.627451   0.42352942 0.00392157 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.31764707 0.9411765  0.99215686\n",
      " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
      " 0.5882353  0.10588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0627451  0.3647059  0.9882353  0.99215686 0.73333335\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.9764706  0.99215686 0.9764706  0.2509804  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
      " 0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15294118 0.5803922\n",
      " 0.8980392  0.99215686 0.99215686 0.99215686 0.98039216 0.7137255\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09411765 0.44705883 0.8666667  0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.7882353  0.30588236 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07058824 0.67058825\n",
      " 0.85882354 0.99215686 0.99215686 0.99215686 0.99215686 0.7647059\n",
      " 0.3137255  0.03529412 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.21568628 0.6745098  0.8862745  0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.95686275 0.52156866 0.04313726 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53333336 0.99215686\n",
      " 0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "(784, 60000)\n"
     ]
    }
   ],
   "source": [
    "#print(data)\n",
    "print(X_train[:,0])\n",
    "print(X_train.shape) #(W * X_train = 10x784 * 784x60000 --> 10*60000 --> 10x10 * 10*60000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e7f9dcf-cb4d-47b0-9d6e-b2152a04069d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights 0: (10, 784)\n",
      "Biases 0: (10, 1)\n",
      "Weights 1: (10, 10)\n",
      "Biases 1: (10, 1)\n",
      "Weights 2: (10, 10)\n",
      "Biases 2: (10, 1)\n"
     ]
    }
   ],
   "source": [
    "mnist_ann = AnnStructure(X_train,[10,10],10)\n",
    "\n",
    "for i in range(len(mnist_ann.W)):\n",
    "    print(f\"Weights {i}: {mnist_ann.W[i].shape}\")\n",
    "    print(f\"Biases {i}: {mnist_ann.b[i].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "120b1f6d-be2b-4cc1-835e-16348891ec7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W[0] = [[0.23606842 0.37974753 0.53434879 ... 0.1454279  0.12504177 0.21201753]\n",
      " [0.96156235 0.80288097 0.08521734 ... 0.59593835 0.03996532 0.96378567]\n",
      " [0.58567659 0.82249459 0.87513819 ... 0.62993649 0.82311927 0.38837362]\n",
      " ...\n",
      " [0.86506744 0.37448257 0.32614976 ... 0.95870243 0.16355594 0.80607039]\n",
      " [0.5089337  0.08943821 0.37241669 ... 0.73014806 0.80910249 0.38313377]\n",
      " [0.31443402 0.96355979 0.62078417 ... 0.54840566 0.75731346 0.97526925]] \n",
      "\n",
      " data = [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] \n",
      "\n",
      "Z_output is: [[2.44778750e-223 5.64590413e-208 9.38498731e-258 ... 2.48363072e-247\n",
      "  5.31787363e-255 6.37179696e-254]\n",
      " [4.03365373e-182 3.83452237e-170 2.56512054e-209 ... 3.27805735e-201\n",
      "  1.29465735e-207 2.15315721e-207]\n",
      " [1.10820148e-229 3.62597530e-215 1.77602925e-264 ... 1.09274648e-254\n",
      "  1.28636956e-262 6.06610691e-262]\n",
      " ...\n",
      " [2.09061986e-215 1.33478977e-200 2.50757563e-247 ... 8.08051893e-238\n",
      "  5.90780335e-245 4.33511525e-244]\n",
      " [1.09082524e-290 1.09282699e-271 0.00000000e+000 ... 8.18666775e-321\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [4.35661732e-170 7.75087375e-159 6.00527920e-196 ... 3.06758616e-188\n",
      "  5.74143991e-194 4.61536013e-194]] \n",
      "Z_output shape is: (10, 60000)\n"
     ]
    }
   ],
   "source": [
    "mnist_ann.feedforward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f72c2914-acaf-4c43-b7ec-771129f49d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.13367935 5.80087549 7.59562912]\n"
     ]
    }
   ],
   "source": [
    "#a = np.array([[1,2,3,4,5]])\n",
    "#b = np.array([[1,0,0],[0,1,0],[0,0,1],[0,1,0],[3,0,0]])\n",
    "\n",
    "a = np.array([1,2,3,4,5])\n",
    "b = np.array([[0.4971655 , 0.46514149, 0.683409  ],[0.34680189 ,0.01691117, 0.64675005],[0.83683601 ,0.93708358, 0.25226605],[0.93013801, 0.49240928, 0.40130433],[0.14237  ,  0.10420476, 0.65134091]])\n",
    "\n",
    "\n",
    "print(np.dot(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eaeb0a0-2de5-4cec-b6a5-e3d4b6521f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Z1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(W1,X_train)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(Z1\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(Z1[:,\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'W1' is not defined"
     ]
    }
   ],
   "source": [
    "Z1 = np.dot(W1,X_train)\n",
    "print(Z1.shape)\n",
    "print(Z1[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4c6a5b-e3b1-4eec-9e57-322fde65083f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = np.array([[[0,1,0],[2,3,0]],[[4,5,4],[6,7,4]]])\n",
    "\n",
    "flattened_array = a.reshape(a.shape[0], -1)\n",
    "print(flattened_array.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bd1f9d-a43f-4b74-91b2-1f5f2ff014aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flattened_array2 = flattened_array.T\n",
    "print(flattened_array.shape)\n",
    "print(len(flattened_array2))\n",
    "print(flattened_array2,\"\\n\\n\")\n",
    "print(flattened_array2[4,1])\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de3a8f-69a6-49dc-90b2-6d6b28786a08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = y_train_raw.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc041f-67ac-4ff9-9b0a-24cb6329442e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A = np.array([1,2,3,4,5,-1,-3])\n",
    "\n",
    "print(A)\n",
    "\n",
    "print(ReLu(A))\n",
    "\n",
    "print(type(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74be2f69-ee6b-4c38-b6ed-c8bb321f5e91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_vars = list(globals().keys())\n",
    "print(\"Global variable names:\", global_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bd03e1-f311-479e-b04d-578473106231",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A3d = np.ones((3, 4, 2))\n",
    "\n",
    "print(A3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930228aa-81dc-415e-8b70-d3c9d592c4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(mnist_ann.W[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee4b8a4-e8d3-4498-babf-604ce96e7015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example usage\n",
    "x = np.array([-1, 2, -3, 4, -5])\n",
    "output = np.maximum(x,0)\n",
    "print(\"Input:\", x)\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e70c2-db86-4c6a-98f6-db9d1238aabb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "A = np.array([[0,1,0,2,1,1],[1,1,1,3,1,0]])\n",
    "print(np.sum(A,axis=-1, keepdims=True))\n",
    "\n",
    "A = softmax([0,1,0,10,1,1])\n",
    "\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8e5950-7100-4f05-a482-31b3e4ff30c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
